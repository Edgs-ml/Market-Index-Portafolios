cor.plot(df1)
cor.plot(df2)
pca_df <- prcomp(df)
summary(pca_df)
pca_df1 <- prcomp(df1)
summary(pca_df1)
pca_df <- prcomp(df)
summary(pca_df)
pca_df1 <- prcomp(df1)
summary(pca_df1)
pca_df2 <- prcomp(df2)
summary(pca_df2)
df_PC1234 <- cbind(df, pca_df$x)
df_PC1234_Descent <- df_PC1234 %>%
arrange(desc(PC1))
df1_PC123 <- cbind(df1, pca_df1$x)
df1_PC123_Descent <- df1_PC123 %>%
arrange(desc(PC1))
df2_PC1234 <- cbind(df2, pca_df2$x)
df2_PC1234_Descent <- df2_PC1234 %>%
arrange(desc(PC1))
pca_df2 <- prcomp(df2)
summary(pca_df2)
pca_df1 <- prcomp(df1)
summary(pca_df1)
df_PC1234 <- cbind(df, pca_df$x)
df_PC1234_Descent <- df_PC1234 %>%
arrange(desc(PC1))
df1_PC123 <- cbind(df1, pca_df1$x)
df1_PC123_Descent <- df1_PC123 %>%
arrange(desc(PC1))
df2_PC1234 <- cbind(df2, pca_df2$x)
df2_PC1234_Descent <- df2_PC1234 %>%
arrange(desc(PC1))
fviz_pca_ind(pca_df,
repel = TRUE,
title = "Place of each country in a PC1 and PC2 Map [With GDP]")
fviz_pca_ind(pca_df1,
repel = TRUE,
title = "Place of each country in a PC1 and PC2 Map [Without GDP]")
fviz_pca_biplot(pca_df)
fviz_pca_biplot(pca_df1)
fviz_pca_biplot(pca_df2)
fviz_contrib(pca_df, choice = "var",
title = "Percentage of Variance contribution With Variable GDP",
addlabels = TRUE)
fviz_contrib(pca_df1, choice = "var",
title = "Percentage of Variance contribution Without Variable GDP",
addlabels = TRUE)
fviz_contrib(pca_df2, choice = "var",
title = "With Variable GDP and without USA & China",
addlabels = TRUE)
fviz_screeplot(pca_df,
title = "4 Principal Components With USA & China",
addlabels = TRUE)
fviz_screeplot(pca_df1,
title = "3 Principal Components Without GDP",
addlabels = TRUE) # Porcentaje de la varianza explicada con el PCA1
fviz_screeplot(pca_df2,
title = "4 Principal Components Without USA & China",
addlabels = TRUE)
fviz_eig(pca_df, choice = "eigenvalue",
addlabels = TRUE,
title = "e")
fviz_eig(pca_df1, choice = "eigenvalue",
addlabels = TRUE,
title = "e")
cor.plot(df_PC1234)
cor.plot(df1_PC123)
cor.plot(df2_PC1234)
map <- fviz_pca_ind(pca_df1)
map
map <- fviz_pca_ind(pca_df1)
map
Kdf1_Descent = subset(df1_PC123_Descent, select = c("PC1","PC2", "PC3"))
head(Kdf1_Descent, 5)
df1_scaled <- scale(df1_PC123_Descent)
set.seed(123)
fviz_nbclust(df1_scaled,
kmeans,
method = "wss",
k.max = 24)
fviz_nbclust(df1_scaled,
kmeans,
method = "gap_stat",
k.max = 30)
#calculate gap statistic based on number of clusters
gap_stat <- clusGap(df1_scaled,
FUN = kmeans,
nstart = 25,
K.max = 30,
B = 50)
#plot number of clusters vs. gap statistic
fviz_gap_stat(gap_stat)
km <- kmeans(Kdf1_Descent, centers = 4, iter.max = 20, nstart = 20)
fviz_cluster(km, data = Kdf1_Descent)#Grafica K means
library(cluster)
library(factoextra) #Para graficar K-Means y PCA
library(psych)
library(stats) #Para hacer el PCA
library(naniar) #Para limpiar las bases de datos
library(fBasics) #Analisis estadistico
library(aTSA) #Raiz Unitaria
library(tseries) #Raiz Unitaria
library(PerformanceAnalytics)
library(QuantPsyc) #Pruba multivariada
library(statmod)
library(ghyp) #Para hacer momentos estadisticos de la NIG
library(quantmod) #Para descargar datos
library(cramer) #Para la prueba de cramer
Serie_de_datos_el_bueno_ <- read_excel("APLHA/ALPHA_1/ALPHA_1.1/1.1.2Normality_Tests/Serie de datos (el bueno).xls",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric"))
g1 <- Serie_de_datos_el_bueno_
colnames(g1)<-c("Fecha","DJI","HSI","OMX20","STI","FTSE")
g1<-textshape::column_to_rownames(g1,loc=1)
g1 <- drop_na(g1)
glimpse(g1)
g1 <- drop_na(g1)
glimpse(g1)
retornos <- Return.calculate(g1,
method = "log")[-1,]
Estg1 <- basicStats(retornos)
Estg1
adf_sti <- adf.test(retornos$STI)
adf_sti_table <- as.data.frame(c(adf_sti$p.value))
adf_sti_table <- adf_sti_table %>%
mutate(method=adf_sti[["method"]])
adf_sti_table <- adf_sti_table %>%
mutate(DF=adf_sti[["statistic"]][["Dickey-Fuller"]])
adf.test(retornos$OMX20)
adf.test(retornos$FTSE)
adf.test(retornos$HSI)
adf.test(retornos$DJI)
m <- mean(retornos$OMX20)
sd <- sd(retornos$OMX20)
len <- length(retornos$OMX20)
basenormal <- dnorm(len,m,sd)
ks.test(retornos$OMX20, basenormal)
ks.test(retornos$STI, basenormal)
ks.test(retornos$FTSE, basenormal)
ks.test(retornos$HSI, basenormal)
ks.test(retornos$DJI, basenormal)
mult.norm(retornos)$mult.test
plot(density(retornos$OMX20),col="blue",ylim=c(0,60), main="Distribuciones contra normal")+
lines(density(retornos$STI),
col="green")+
lines(density(retornos$FTSE),
col="orange")+
lines(density(retornos$HSI),
col="black")+
lines(density(retornos$DJI),
col="grey")+
lines(density(basenormal),
col="red")
#Parametros de la NIG
NIG<-nigFit(retornos$STI)
#Agrupar parametros en un objeto
a<-NIG@fit[["par"]]
a<-data.frame(t(a))
#NIG aleatoria con parametors univariados de nuestra serie
r = rnig(len,
alpha = a$alpha ,
beta = a$beta,
delta = a$delta ,
mu= a$mu)
plot(density(r),
col="red",
main="NIG Univariada",
sub="STI index")
#Pruba de Kormogorov univariada para NIG
ks.test(retornos$STI,r)
#Parametros para NIG Multivariada
multNIG <- fit.NIGmv(data=retornos,
silent=FALSE)
#Localizar parametros dentor de un obejto
Mom1NIGm <- multNIG@expected.value
Mom2NIGm <- multNIG@variance
#Construccion de la funcion NIG con nuestros  parametros de la funcion multivariada
Mnig <- rghyp(len, multNIG)
retornos1 <- as.matrix(retornos)
#Prueba cramer de comprobacion
#Se buscan similitudes estadisticas
cramer.test(Mnig,
retornos1,
conf.level = .95)
plot(density(Mnig),col="red",ylim=c(0,60),main="Distribuciones contra NIG multivariada")+
lines(density(retornos$OMX20),col="green")+
lines(density(retornos$FTSE),col="purple")+
lines(density(retornos$HSI),col="black")+
lines(density(retornos$DJI),col="dark blue")+
lines(density(retornos$STI),col="pink")
Specs_Port <- portfolio.spec(c("DJI",	"HSI",	"OMX20",	"STI",	"FTSE"))
Specs_Port <- portfolio.spec(c("DJI",	"HSI",	"OMX20",	"STI",	"FTSE"))
library(tidyverse)
library(readxl)
library(textshape) #"Tools for Reshaping Text". Usado en columns_to_rownames
library(broom)
library(plotly)
library(scales)
library(caTools)
library(caret)
library(cluster)
library(factoextra) #Para graficar K-Means y PCA
library(psych) #Usado por su funsiÃ³n de crar matices de correlaciones de colores
library(stats) #Para hacer el PCA
library(naniar) #Para limpiar las bases de datos
library(fBasics) #Analisis estadistico
library(PerformanceAnalytics)
library(statmod)
library(knitr)
df <- read_excel("APLHA/ALPHA_1/ALPHA_1.1/1.1.1PCA_Codes/Criterios-Unificado (Datos para PCA).xlsx")
#df2: eliminar a China y Estados Unidos
df2 <- df %>%
subset(Country!="China" & Country!="United States")
#df: Data Frame with all variables and observations
df <- column_to_rownames(df, loc = 1)
#df1: Data frame without GDP and with all the countries
df1 <- df[,-4]
#df2: Data Frame without China and USA and with GDP
df2 <- column_to_rownames(df2, loc = 1)
describe(df)
describe(df1)
describe(df2)
describe(df2)
cor.plot(df)
cor.plot(df1)
cor.plot(df2)
pca_df <- prcomp(df)
summary(pca_df)
pca_df1 <- prcomp(df1)
summary(pca_df1)
pca_df2 <- prcomp(df2)
summary(pca_df2)
df_PC1234 <- cbind(df, pca_df$x)
df_PC1234_Descent <- df_PC1234 %>%
arrange(desc(PC1))
df1_PC123 <- cbind(df1, pca_df1$x)
df1_PC123_Descent <- df1_PC123 %>%
arrange(desc(PC1))
df2_PC1234 <- cbind(df2, pca_df2$x)
df2_PC1234_Descent <- df2_PC1234 %>%
arrange(desc(PC1))
fviz_pca_ind(pca_df,
repel = TRUE,
title = "Place of each country in a PC1 and PC2 Map [With GDP]")
fviz_pca_ind(pca_df1,
repel = TRUE,
title = "Place of each country in a PC1 and PC2 Map [Without GDP]")
"quitar los nombres de los puntos"
fviz_pca_ind(pca_df2,
repel = TRUE,
title = "Place of each country [With GDP and without USA & China]")
fviz_pca_biplot(pca_df)
fviz_pca_biplot(pca_df1)
fviz_pca_biplot(pca_df2)
fviz_contrib(pca_df, choice = "var",
title = "Percentage of Variance contribution With Variable GDP",
addlabels = TRUE)
fviz_contrib(pca_df1, choice = "var",
title = "Percentage of Variance contribution Without Variable GDP",
addlabels = TRUE)
fviz_contrib(pca_df, choice = "var",
title = "Percentage of Variance contribution With Variable GDP",
addlabels = TRUE)
fviz_contrib(pca_df2, choice = "var",
title = "With Variable GDP and without USA & China",
addlabels = TRUE)
fviz_screeplot(pca_df,
title = "4 Principal Components With USA & China",
addlabels = TRUE)
fviz_screeplot(pca_df1,
title = "3 Principal Components Without GDP",
addlabels = TRUE) # Porcentaje de la varianza explicada con el PCA1
fviz_eig(pca_df, choice = "eigenvalue",
addlabels = TRUE,
title = "e")
fviz_eig(pca_df1, choice = "eigenvalue",
addlabels = TRUE,
title = "e")
fviz_eig(pca_df2, choice = "eigenvalue",
addlabels = TRUE,
title = "e")
cor.plot(df_PC1234)
cor.plot(df1_PC123)
cor.plot(df2_PC1234)
map <- fviz_pca_ind(pca_df1)
map
Kdf1_Descent = subset(df1_PC123_Descent, select = c("PC1","PC2", "PC3"))
head(Kdf1_Descent, 5)
df1_scaled <- scale(df1_PC123_Descent)
set.seed(123)
fviz_nbclust(df1_scaled,
kmeans,
method = "wss",
k.max = 24)
fviz_nbclust(df1_scaled,
kmeans,
method = "gap_stat",
k.max = 30)
#calculate gap statistic based on number of clusters
gap_stat <- clusGap(df1_scaled,
FUN = kmeans,
nstart = 25,
K.max = 30,
B = 50)
#plot number of clusters vs. gap statistic
fviz_gap_stat(gap_stat)
km <- kmeans(Kdf1_Descent, centers = 4, iter.max = 20, nstart = 20)
fviz_cluster(km, data = Kdf1_Descent)#Grafica K means
library(cluster)
library(factoextra) #Para graficar K-Means y PCA
library(psych)
library(stats) #Para hacer el PCA
library(naniar) #Para limpiar las bases de datos
library(fBasics) #Analisis estadistico
library(aTSA) #Raiz Unitaria
library(tseries) #Raiz Unitaria
library(PerformanceAnalytics)
library(QuantPsyc) #Pruba multivariada
library(statmod)
library(ghyp) #Para hacer momentos estadisticos de la NIG
library(quantmod) #Para descargar datos
library(cramer) #Para la prueba de cramer
Serie_de_datos_el_bueno_ <- read_excel("APLHA/ALPHA_1/ALPHA_1.1/1.1.2Normality_Tests/Serie de datos (el bueno).xls",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric"))
g1 <- Serie_de_datos_el_bueno_
colnames(g1)<-c("Fecha","DJI","HSI","OMX20","STI","FTSE")
g1<-textshape::column_to_rownames(g1,loc=1)
g1 <- drop_na(g1)
glimpse(g1)
retornos <- Return.calculate(g1,
method = "log")[-1,]
Estg1 <- basicStats(retornos)
Estg1
adf_sti <- adf.test(retornos$STI)
adf_sti_table <- as.data.frame(c(adf_sti$p.value))
adf_sti_table <- adf_sti_table %>%
mutate(method=adf_sti[["method"]])
adf_sti_table <- adf_sti_table %>%
mutate(DF=adf_sti[["statistic"]][["Dickey-Fuller"]])
adf.test(retornos$OMX20)
adf.test(retornos$FTSE)
adf.test(retornos$HSI)
adf.test(retornos$DJI)
m <- mean(retornos$OMX20)
sd <- sd(retornos$OMX20)
len <- length(retornos$OMX20)
basenormal <- dnorm(len,m,sd)
ks.test(retornos$OMX20, basenormal)
ks.test(retornos$STI, basenormal)
ks.test(retornos$FTSE, basenormal)
ks.test(retornos$HSI, basenormal)
ks.test(retornos$DJI, basenormal)
mult.norm(retornos)$mult.test
plot(density(retornos$OMX20),col="blue",ylim=c(0,60), main="Distribuciones contra normal")+
lines(density(retornos$STI),
col="green")+
lines(density(retornos$FTSE),
col="orange")+
lines(density(retornos$HSI),
col="black")+
lines(density(retornos$DJI),
col="grey")+
lines(density(basenormal),
col="red")
#Parametros de la NIG
NIG<-nigFit(retornos$STI)
#Agrupar parametros en un objeto
a<-NIG@fit[["par"]]
a<-data.frame(t(a))
#NIG aleatoria con parametors univariados de nuestra serie
r = rnig(len,
alpha = a$alpha ,
beta = a$beta,
delta = a$delta ,
mu= a$mu)
plot(density(r),
col="red",
main="NIG Univariada",
sub="STI index")
#Pruba de Kormogorov univariada para NIG
ks.test(retornos$STI,r)
plot(density(Mnig),col="red",ylim=c(0,60),main="Distribuciones contra NIG multivariada")+
lines(density(retornos$OMX20),col="green")+
lines(density(retornos$FTSE),col="purple")+
lines(density(retornos$HSI),col="black")+
lines(density(retornos$DJI),col="dark blue")+
lines(density(retornos$STI),col="pink")
Specs_Port <- portfolio.spec(c("DJI",	"HSI",	"OMX20",	"STI",	"FTSE"))
library(quantmod)
library(PerformanceAnalytics)
library(PortfolioAnalytics)
library(DEoptim)
library(readxl)
library(fBasics)
library(ghyp)
g1<- read_excel("D:/JL/Market-Index-Portafolios/APLHA/ALPHA 1/ALPHA 1.1/1.1.3Portafolio_Optimization/Optimizacion en excel/NIG/Optimizacion (el bueno1).xlsx",
sheet = "Datos")
Specs_Port <- portfolio.spec(c("DJI",	"HSI",	"OMX20",	"STI",	"FTSE"))
##### Add Constraints #####
Specs_Port <- add.constraint(Specs_Port,type="full_investment")
Specs_Port <- add.constraint(Specs_Port,type="long_only")
##### Add Objective #####
Specs_Port <- add.objective(Specs_Port,type="risk",name="StdDev")
Specs_Port <- add.objective(Specs_Port,type='return',name='mean')
Specs_Port
View(Specs_Port)
plot(density(retornos$OMX20),col="blue",ylim=c(0,60), main="Distribuciones contra normal")+
lines(density(retornos$STI),
col="green")+
lines(density(retornos$FTSE),
col="orange")+
lines(density(retornos$HSI),
col="black")+
lines(density(retornos$DJI),
col="grey")+
lines(density(basenormal),
col="red")
plot(density(retornos$OMX20),col="blue",ylim=c(0,60), main="Distribuciones contra normal")
plot(density(retornos$OMX20),
col="blue",
ylim=c(0,60),
main="Distribuciones contra normal")+
lines(density(retornos$DJI),
col(="red"))
lines(density(retornos$DJI)
plot(density(retornos$OMX20),
plot(density(retornos$OMX20),
col="blue",
ylim=c(0,60),
main="Distribuciones contra normal")
plot(density(retornos$DJI),
col="red",
ylim=c(0,60),
main="Distribuciones contra normal")
plot(density(retornos$OMX20),
col="blue",
ylim=c(0,60),
main="Distribuciones contra normal")+plot(density(retornos$DJI),
col="red",
ylim=c(0,60),
main="Distribuciones contra normal")
plot(density(retornos$OMX20),
col="blue",
ylim=c(0,60),
main="Distribuciones contra normal")+plot(density(retornos$DJI),
col="red",
ylim=c(0,60))
plot(density(retornos$OMX20),
col="blue",
ylim=c(0,60),
main="Distribuciones contra normal")+lines(density(retornos$DJI),
col="red",
ylim=c(0,60))
library(quantmod)
library(PerformanceAnalytics)
library(PortfolioAnalytics)
library(DEoptim)
library(readxl)
library(fBasics)
library(ghyp)
plot(density(retornos$OMX20),
col="blue",
ylim=c(0,60),
main="Distribuciones contra normal")+
lines(density(retornos$DJI),
col="red",
ylim=c(0,60))+
lines(density(retornos$HSI),
col="orange",
ylim=c(0,60))+
lines(density(retornos$STI),
col="green",
ylim=c(0,60))+
lines(density(retornos$FTSE),
col="black",
ylim=c(0,60))
library(quantmod)
library(PerformanceAnalytics)
library(PortfolioAnalytics)
library(DEoptim)
library(readxl)
library(fBasics)
library(ghyp)
install.packages("GeneralizedHyperbolic")
DFOpt1Norm <- read_excel("~/Documents/GitHub/Market-Index-Portafolios/iNDICES.xlsx")
View(DFOpt1Norm)
DFOpt1Norm <- read_excel("~/Documents/GitHub/Market-Index-Portafolios/iNDICES.xlsx",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric"))
DFOpt1Norm <- read_excel("~/Documents/GitHub/Market-Index-Portafolios/iNDICES.xlsx",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric", "numeric", "numeric"))
View(DFOpt1Norm)
View(DFOpt1Norm)
DFOpt1Norm <- read_excel("~/Documents/GitHub/Market-Index-Portafolios/iNDICES.xlsx",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric", "numeric", "numeric"))
colnames(DFOpt1Norm) <- ("Fecha","SP","OMX30","HSI","STI","KOSPI","DAX")
colnames(DFOpt1Norm) <- ("Fecha", "SP", "OMX30", "HSI", "STI", "KOSPI", "DAX")
colnames(g1)<-c("Fecha","DJI",	"HSI",	"OMX20",	"STI",	"FTSE")
View(g1)
Specs_Port <- portfolio.spec(c("DJI",	"HSI",	"OMX20",	"STI",	"FTSE"))
##### Add Constraints #####
Specs_Port <- add.constraint(Specs_Port,type="full_investment")
Specs_Port <- add.constraint(Specs_Port,type="long_only")
##### Add Objective #####
Specs_Port <- add.objective(Specs_Port,type="risk",name="StdDev")
Specs_Port <- add.objective(Specs_Port,type='return',name='mean')
Specs_Port
