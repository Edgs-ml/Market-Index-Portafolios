plot <- colony %>%
filter(months %in% c("January-March", "October-December")) %>%
group_by(state) %>%
summarise(mean_loss = mean(colony_lost_pct, na.rm = TRUE)) %>%
mutate(mean_loss = mean_loss / 100) %>%
right_join(spdf_fortified, by = c("state" = "id")) %>%
filter(!state %in% c("United States", "Other States", "Alaska", "Hawaii")) %>%
left_join(merge, by = c("state" = "google_name")) %>%
left_join(centers, by = c("iso3166_2" = "id")) %>%
ggplot() +
geom_polygon(aes(x = long, y = lat, group = group, fill = mean_loss), colour = "#312f17", size = 2) +
theme_void() +
coord_map() +
geom_text(aes(x = x,
y = y,
label = ifelse(
is.na(mean_loss),
paste0(iso3166_2, "\n", NA),
paste0(iso3166_2, "\n", scales::percent(mean_loss, accuracy = 1L)))),
color="black",
size = 6,
family = "Century Gothic") +
scale_fill_stepsn(
colours = c("#ffdf77", "#fccf3e","#e5ac3f", "#f55f20"),
breaks = c(0.05, 0.1, 0.15, 0.2),
na.value = "white",
labels = scales::percent_format(accuracy = 5L)
) +
theme(plot.title = element_text(size = 32, family = "Century Gothic", face = "bold"),
plot.background = element_rect(fill = "#F8F5E6", colour = "#F8F5E6"),
plot.subtitle = element_text(size = 16, family = "Century Gothic"),
legend.title = element_text(size = 16, hjust = 0.5, vjust = 0.7, family = "Century Gothic"),
legend.text = element_text(size = 12, hjust = -0.1, family = "Century Gothic"),
legend.position = "bottom",
legend.key.size = unit(1, 'cm'),
plot.margin=unit(c(1,1,1,1),"cm"),
plot.caption = element_text(size = 10, family= "Century Gothic")) +
labs(title = "\n\nBeekeepers facing harsh colony losses over Winter Months",
subtitle = "\nMean % of Bee Colonies lost over Winter Months (1st October to 31st March) from 2015 to 2021",
fill = "Mean Loss %",
caption = "Visualisation | Henry Wakefield\nTwitter | @henrywrover2\n Data | USDA\nSource | https://usda.library.cornell.edu/concern/publications/rn301137d\n\n")
library(tidyverse)
library(broom)
install.packages("broom", type="binary")
library(tidyverse)
library(broom)
colony <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-11/colony.csv')
library(extrafontdb)
library(tidyverse)
library(geojsonio)
library(RColorBrewer)
library(rgdal)
library(broom)
# Correlación
library(tidyverse)
# Correlación
install.packages('fansi')
library(tidyverse)
library(readxl)
cor <- read_excel("Downloads/cor.xlsx", col_types = c("date",
"numeric", "numeric", "numeric", "numeric",
"text", "numeric", "text", "text"))
View(cor)
View(cor)
corna <- drop_na(cor)
view(corna)
cor.test(Price, Precio, data=corna)
cor.test(corna$Price, corna$Precio)
cor.test(corna$Price, as.numeric(corna$Precio)
cor.test(corna$Price, as.numeric(corna$Precio))
library(extrafontdb)
library(tidyverse)
library(geojsonio)
library(RColorBrewer)
library(rgdal)
library(broom)
library(rgeos)
install.packages("broom", type="binary")
install.packages("broom", type = "binary")
colony <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-11/colony.csv')
View(colony)
spdf <- geojson_read("us_states_hexgrid.geojson",  what = "sp")
spdf@data <- spdf@data %>%
mutate(google_name = gsub(" \\(United States\\)", "", google_name))
library(extrafontdb)
library(tidyverse)
library(geojsonio)
package:base
install.packages("geojsonio")
install.packages("geojsonio")
library(RColorBrewer)
library(rgdal)
install.packages("sp")
install.packages("sp")
library(rgdal)
spdf <- geojson_read("us_states_hexgrid.geojson",  what = "sp")
library(rgeos)
library(broom)
library(rgdal)
library(RColorBrewer)
library(geojsonio)
install.packages('rmapshaper')
library(geojsonio)
spdf <- geojson_read("us_states_hexgrid.geojson",  what = "sp")
colony <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-11/colony.csv')
spdf <- geojson_read("us_states_hexgrid.geojson",  what = "sp")
install.packages("MetBrewer")
#### 1
library(tidyverse)
library(quantmod)
library(rvest)
url <-"https://finance.yahoo.com/quote/AAPL?p=AAPL&.tsrc=fin-srch"
page <-read_html(url)
View(page)
url <-"https://finance.yahoo.com/quote/AAPL/options?p=AAPL"
page <-read_html(url)
Calls <-page %>%
html_node(".calls") %>%
html_table()
Calls
View(Calls)
html_table()?
?html_table()
##### Cargar librer?as #####
library(quantmod)
library(PerformanceAnalytics)
library(tidyverse)
library(forecast)
install.packages("forecast")
library(forecast)
install.packages("PerforrmanceAnalytivs")
library(tseries)
install.packages("tseries")
install.packages("tseries")
library(tseries)
##### Cargar tokens de series financieras #####
# Los tickers pueden ser encontrados en yahoo finance
getSymbols("BTC-USD") #quantmod
##### Cargar librer?as #####
library(quantmod)
install.packages("zoo")
install.packages("zoo")
##### Cargar librer?as #####
library(quantmod)
library(zoo)
##### Cargar librer?as #####
library(quantmod)
##### Cargar tokens de series financieras #####
# Los tickers pueden ser encontrados en yahoo finance
getSymbols("BTC-USD") #quantmod
getSymbols("ETH-USD") # Usar el precio ajustado
getSymbols("DOGE-USD") # Precio Ajustado = Precio de cierre - Dividendos
getSymbols("ADA-USD")
getSymbols("BNB-USD")
##### Visualizaci?n de series #####
# Las gr?ficas por default son velas japonesas
chartSeries(`BTC-USD`)
##### Extracci?n de variables #####
# Cada ticker es descargado con distintas variables
# El precio ajustado es el que se suele usar para an?lisis
# Para extraer esta variable desde el objeto se usa Ad()
# Se almacena en un nuevo objeto para facilitar el an?lisis
btc <- Ad(`BTC-USD`)
# Limpiar de valores faltantes NA
# Criterio Last Observation Carried Forward
btc <- na.locf(btc)
Rendimientos_D <- Return.calculate(btc,
method = "discrete")[-1]
library(readxl)
library(fBasics)#Analisis estadistico
library(aTSA)#Raiz Unitaria
library(tseries)#Raiz Unitaria
library(naniar)#remueve Nas
library(tidyverse)#Ya incluye read excel
library(PerformanceAnalytics)
library(textshape)
library(QuantPsyc)#Pruba multivariada de normlaidad
library(statmod)
library(ghyp)#multivariado NIG
library(cramer)#Pruba cramer NIG multivariada
library(tidyr)
library(dplyr)
g1<- read_excel("Documents/GitHub/Market-Index-Portafolios/A-1 Index Group 1/A -1.2 Index Group/Correlaciones A - 1.2/Charting Excel Export - Jan 21st 2022 11_27_13 pm.xls",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric"))
library(readxl)
Charting_Excel_Export_Jan_21st_2022_11_27_13_pm <- read_excel("Documents/GitHub/Market-Index-Portafolios/A-1 Index Group 1/A -1.2 Index Group/Correlaciones A - 1.2/Charting Excel Export - Jan 21st 2022 11_27_13 pm.xls",
col_types = c("date", "numeric", "numeric",
"numeric", "numeric", "numeric"))
View(Charting_Excel_Export_Jan_21st_2022_11_27_13_pm)
g1<- Charting_Excel_Export_Jan_21st_2022_11_27_13_pm
colnames(g1)<-c("Fecha","OMX 20","STI","FTSE 100","HSI","DJI")
g1<-textshape::column_to_rownames(g1,loc=1)
g1<-drop_na(g1)
glimpse(g1)
retornos<-Return.calculate(g1,method = "log")
retornos<- retornos[-1,]
Estg1<-basicStats(retornos)
Estg1
adf.test(retornos$STI)
#Prubas de Kormogorov contra distribucion normal, creada con paramaetros de nuestra serie
ks.test(retornos$OMX.20,basenormal)
m<-mean(retornos$OMX.20)
sd<-sd(retornos$OMX.20)
len<-length(retornos$OMX.20)
basenormal<-rnorm(len,m,sd)
#Prubas de Kormogorov contra distribucion normal, creada con paramaetros de nuestra serie
ks.test(retornos$OMX.20,basenormal)
mult.norm(retornos)$mult.test
